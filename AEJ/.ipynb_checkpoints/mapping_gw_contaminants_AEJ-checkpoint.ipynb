{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Mapping Groundwater Contaminants of California\n",
    "\n",
    "Potential goals of this notebook:\n",
    "1. Clean the dataset into a workable dataframe\n",
    "2. Spatially plot the data using geopandas, or cartopy\n",
    "3. ...\n",
    "\n",
    "## 1. Reorganizing the data\n",
    "\n",
    "This first section will deal with cleaning and reorganizing the data. \n",
    "\n",
    "(The `%matplotlib inline` syntax prints out the figures that are created after each specific call.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "## Set the data's directory path\n",
    "script_dir = os.path.abspath('')\n",
    "data_dir   = os.path.join( os.path.split(os.path.split(script_dir)[0])[0], # shared path\n",
    "                           'whw2019_India GW Code & Data\\\\whw2019_NWQData' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are using for this analysis are from a collaboration between the United States Geological Survey ([USGS](https://www.usgs.gov/)), the Environmental Protection Agency([EPA](https://www.epa.gov/)), United States Department of Agriculture Agricultural Reaseach Service ([USDA ARS](https://www.ars.usda.gov/)), and the National Water Quality Monitoring Council ([NWQMC](https://acwi.gov/monitoring/)). The groundwater quality data was aggragated and downloaded from the [Water Quality Portal](https://www.waterqualitydata.us/coverage/). \n",
    "\n",
    "The reported data sources are:\n",
    "* National Water Information System ([NWIS](https://waterdata.usgs.gov/nwis)) - USGS\n",
    "* STOrage and RETrieval ([STORET](https://www.epa.gov/waterdata/water-quality-data-wqx)) Data Warehouse - EPA\n",
    "* Sustaining The Earth's Watersheds - Agricultural Research Database System ([STEWARDS]())\n",
    "\n",
    "For now the state/region of interest is California (CA). However, we hope to be able to apply similar analyses to other states around the US, or to other countries (e.g., India) should adequate spatial (X,Y,Z) and temporal data resolution be available.\n",
    "\n",
    "To read in the datafiles, we must make the proper call toward their storage location (on Hydroshare). The following `pd.read_csv` commands may present with some warnings after running. In this instance, the warnings are fine to ignore (however, always be mindful of the coding issues). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (9,10,11,12,13,14,16,18,19,23,33,37,39,42,47,57,59,61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\allan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Enter state code in 'state' variable to read in that states data results.\n",
    "state = 'CA'\n",
    "results  = pd.read_csv(r'{}\\\\{}_result.csv'.format(data_dir, state))\n",
    "stations = pd.read_csv(r'{}\\\\{}_station.csv'.format(data_dir, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.drop(columns=['OrganizationIdentifier', \n",
    "                      'OrganizationFormalName',\n",
    "                      'ActivityIdentifier', \n",
    "                      'ActivityTypeCode', \n",
    "                      'ActivityMediaName',\n",
    "                      'ActivityMediaSubdivisionName',\n",
    "                      'ResultStatusIdentifier', \n",
    "                      'StatisticalBaseCode', \n",
    "                      'ResultValueTypeName',\n",
    "                      'ResultWeightBasisText', \n",
    "                      'ResultTimeBasisText',\n",
    "                      'ResultTemperatureBasisText',\n",
    "                      'ResultParticleSizeBasisText',\n",
    "                      'PrecisionValue', \n",
    "                      'ResultCommentText',\n",
    "                      'USGSPCode',\n",
    "                      'ResultDepthHeightMeasure/MeasureValue',\n",
    "                      'ResultDepthHeightMeasure/MeasureUnitCode',\n",
    "                      'ResultDepthAltitudeReferencePointText', \n",
    "                      'SubjectTaxonomicName',\n",
    "                      'SampleTissueAnatomyName',\n",
    "                      'ResultAnalyticalMethod/MethodIdentifier',\n",
    "                      'ResultAnalyticalMethod/MethodIdentifierContext',\n",
    "                      'ResultAnalyticalMethod/MethodName', \n",
    "                      'MethodDescriptionText',\n",
    "                      'LaboratoryName',\n",
    "                      'AnalysisStartDate', \n",
    "                      'ResultLaboratoryCommentText',\n",
    "                      'DetectionQuantitationLimitTypeName',\n",
    "                      'DetectionQuantitationLimitMeasure/MeasureValue',\n",
    "                      'DetectionQuantitationLimitMeasure/MeasureUnitCode',\n",
    "                      'PreparationStartDate', \n",
    "                      'ProviderName',\n",
    "                      'ProjectIdentifier',\n",
    "                      'ActivityConductingOrganizationText',\n",
    "                      'ActivityCommentText',\n",
    "                      'MeasureQualifierCode', \n",
    "                      'SampleCollectionMethod/MethodIdentifier',\n",
    "                      'SampleCollectionMethod/MethodIdentifierContext',\n",
    "                      'SampleCollectionMethod/MethodName',\n",
    "                      'SampleCollectionEquipmentName',\n",
    "                      'ResultDetectionConditionText'\n",
    "                     ], inplace=True)\n",
    "\n",
    "# # preview the data\n",
    "# results.head()\n",
    "# stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After uploading/reading the .csv file as a `Pands` dataframe, we dropped unnecessary column values (above). The next step is to merge the two data frames `results` and `stations` by the station identifier to obtain a unified dataframe.\n",
    "\n",
    "We have reset the \"headers\" of the rows to be the 'MonitoringLocationIdentifier' for each station. The new variable `mwd` stands for \"merged well dataframe\".\n",
    "\n",
    "The bounding box for Califonia was obtained [here](https://gist.github.com/jakebathman/719e8416191ba14bb6e700fc2d5fccc5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# california bounding box information\n",
    "ca_max_lon = -114.1315\n",
    "ca_min_lon = -124.6509\n",
    "ca_max_lat = 42.0126\n",
    "ca_min_lat = 32.5121\n",
    "\n",
    "# creat boolean conditional statements\n",
    "lon_condition = (ca_min_lon <= stations['LongitudeMeasure']) & (stations['LongitudeMeasure'] <= ca_max_lon)\n",
    "lat_condition = (ca_min_lat <= stations['LatitudeMeasure']) & (stations['LatitudeMeasure'] <= ca_max_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for removal of inaccurate points\n",
    "# stations.shape\n",
    "\n",
    "# clean the data to drop stations outside the bounding box of California\n",
    "stations = stations.loc[ (lat_condition & lon_condition) ,:]\n",
    "\n",
    "# Check for removal of inaccurate points\n",
    "# stations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwd = stations.merge( results, on='MonitoringLocationIdentifier' )\n",
    "mwd = mwd.set_index( 'MonitoringLocationIdentifier' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a `Pandas` dataframe, I want to convert the dataframe to a geopandas dataframe.\n",
    "\n",
    "If this is your first time using `GeoPandas`, you may need to install `GeoPandas`. The simplest way to do this is to use your `anaconda prompt` to call on a miniconda installation to download `GeoPandas` from `conda-forge`.\n",
    "\n",
    "Essentially, enter the following into your `anaconda prompt` command shell:\n",
    "`conda install -c conda-forge geopandas`\n",
    "\n",
    "The installation make take a minute. Be patient - go grab coffee or something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Convert the DataFrame's Lat/Long coordinates into the appropriate shapely geometries\n",
    "gpdgeom = [Point(xy) for xy in zip(mwd.LongitudeMeasure, mwd.LatitudeMeasure)]\n",
    "\n",
    "# convert the dataframe to a geopandas dataframe\n",
    "crs = {'init': 'epsg:4326'} # coordinate reference system -> 4326 - web mercator projection\n",
    "# could also choose to be in UTM for CA?\n",
    "mwgd = gpd.GeoDataFrame(mwd, crs=crs, geometry=gpdgeom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a `GeoPandas` geodataframe, we can begin to spatially plot the data over a map of California (or our area of interest).\n",
    "\n",
    "However, the first step in the process will be to subset the data before plotting.\n",
    "\n",
    "* Date - 'ActivityStartDate'\n",
    "* Sample value - 'ResultMeasureValue'\n",
    "\n",
    "Look into 'tidy data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OrganizationIdentifier', 'OrganizationFormalName',\n",
       "       'MonitoringLocationName', 'MonitoringLocationTypeName',\n",
       "       'MonitoringLocationDescriptionText', 'HUCEightDigitCode',\n",
       "       'DrainageAreaMeasure/MeasureValue',\n",
       "       'DrainageAreaMeasure/MeasureUnitCode',\n",
       "       'ContributingDrainageAreaMeasure/MeasureValue',\n",
       "       'ContributingDrainageAreaMeasure/MeasureUnitCode', 'LatitudeMeasure',\n",
       "       'LongitudeMeasure', 'SourceMapScaleNumeric',\n",
       "       'HorizontalAccuracyMeasure/MeasureValue',\n",
       "       'HorizontalAccuracyMeasure/MeasureUnitCode',\n",
       "       'HorizontalCollectionMethodName',\n",
       "       'HorizontalCoordinateReferenceSystemDatumName',\n",
       "       'VerticalMeasure/MeasureValue', 'VerticalMeasure/MeasureUnitCode',\n",
       "       'VerticalAccuracyMeasure/MeasureValue',\n",
       "       'VerticalAccuracyMeasure/MeasureUnitCode',\n",
       "       'VerticalCollectionMethodName',\n",
       "       'VerticalCoordinateReferenceSystemDatumName', 'CountryCode',\n",
       "       'StateCode', 'CountyCode', 'AquiferName', 'FormationTypeText',\n",
       "       'AquiferTypeName', 'ConstructionDateText',\n",
       "       'WellDepthMeasure/MeasureValue', 'WellDepthMeasure/MeasureUnitCode',\n",
       "       'WellHoleDepthMeasure/MeasureValue',\n",
       "       'WellHoleDepthMeasure/MeasureUnitCode', 'ProviderName',\n",
       "       'ActivityStartDate', 'ActivityStartTime/Time',\n",
       "       'ActivityStartTime/TimeZoneCode', 'ActivityEndDate',\n",
       "       'ActivityEndTime/Time', 'ActivityEndTime/TimeZoneCode',\n",
       "       'ActivityDepthHeightMeasure/MeasureValue',\n",
       "       'ActivityDepthHeightMeasure/MeasureUnitCode',\n",
       "       'ActivityDepthAltitudeReferencePointText',\n",
       "       'ActivityTopDepthHeightMeasure/MeasureValue',\n",
       "       'ActivityTopDepthHeightMeasure/MeasureUnitCode',\n",
       "       'ActivityBottomDepthHeightMeasure/MeasureValue',\n",
       "       'ActivityBottomDepthHeightMeasure/MeasureUnitCode', 'SampleAquifer',\n",
       "       'HydrologicCondition', 'HydrologicEvent', 'CharacteristicName',\n",
       "       'ResultSampleFractionText', 'ResultMeasureValue',\n",
       "       'ResultMeasure/MeasureUnitCode', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mwgd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Basin and Range basin-fill aquifers', nan,\n",
       "       'California Coastal Basin aquifers', 'Other aquifers',\n",
       "       'Pacific Northwest basin-fill aquifers',\n",
       "       'Central Valley aquifer system',\n",
       "       'Basin and Range carbonate-rock aquifers',\n",
       "       'Pacific Northwest volcanic-rock aquifers'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mwgd['AquiferName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-03-07'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mwgd['ActivityStartDate'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure Goals\n",
    "\n",
    "1. Plot arsenic (or other contaminant) by aquifer across the state for 2015, during the major drought the persisted from 2011-2017.\n",
    "2. Plot for each year from 2011-2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# create a column of datetime variables\n",
    "mwgd['ActivityStartDate'] = pd.to_datetime( mwgd['ActivityStartDate'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add row of values scaling As by the MCL\n",
    "def determine_MCL( chemical ):\n",
    "    if chemical == 'Arsenic':\n",
    "        MCL_value = 0.010\n",
    "    elif chemical == 'Nitrate':\n",
    "        MCL_value = 45\n",
    "    elif chemical == 'Chromium':\n",
    "        MCL_value = 0.05\n",
    "    elif chemical == 'Uranium':\n",
    "        MCL_value = 0.030\n",
    "    elif chemical == 'Selenium':\n",
    "        MCL_value = 0.050\n",
    "    elif chemical == 'Flouride':\n",
    "        MCL_value = 2.0\n",
    "    elif chemical == 'Total Dissolved Solids':\n",
    "        MCL_value = 500\n",
    "    elif chemical == 'Manganese':\n",
    "        MCL_value = 0.05\n",
    "    elif chemical == 'Iron':\n",
    "        MCL_value = 0.3\n",
    "    elif chemical == '0.15':\n",
    "        MCL_value = 0.015\n",
    "    return MCL_value\n",
    "\n",
    "# above function returns the given MCL for the contaminant in mg/L\n",
    "\n",
    "# ***** # building function to convert concentration data\n",
    "# def convert_concentration( value_zip ):\n",
    "#     for value, units in value_zip:\n",
    "#         if 'mg' not in units:\n",
    "#             if 'ug' in units: # micro-grams\n",
    "#                 value = value/1e3\n",
    "#     return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to add a functionality that converts concentrations to proper units\n",
    "\n",
    "When using chemicals/contaminants/characteristics other than Arsenic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\allan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# obtain all the samples during the year 2015\n",
    "annual_cond = ( (mwgd['ActivityStartDate'] > datetime(2014,12,31)) &\n",
    "                (mwgd['ActivityStartDate'] < datetime(2016, 1, 1)) )\n",
    "annual_subset = mwgd.loc[ annual_cond, : ]\n",
    "\n",
    "# clean list of aquifers\n",
    "# i.e., subset to remove \"nan\" and \"Other Aquifers\" listings\n",
    "aquifer_cond = ( ( ~pd.isnull(annual_subset['AquiferName']) ) )# &\n",
    "#                  (annual_subset['AquiferName'] != 'Other aquifers') )\n",
    "aqui_ann_subset = annual_subset.loc[ (aquifer_cond), : ]\n",
    "\n",
    "# obtain all As rows\n",
    "chem_of_int = 'Arsenic'\n",
    "MCL_value = determine_MCL( chem_of_int )\n",
    "chem_cond = aqui_ann_subset['CharacteristicName']  == 'Arsenic' \n",
    "chem_aqui_ann_subset = aqui_ann_subset.loc[ (chem_cond) ,:]\n",
    "\n",
    "# convert Result measure value\n",
    "chem_aqui_ann_subset['ConvertedResultMeasureValue']  = chem_aqui_ann_subset['ResultMeasureValue']/1e3\n",
    "chem_aqui_ann_subset['NormalizedResultMeasureValue'] = chem_aqui_ann_subset['ConvertedResultMeasureValue']/MCL_value\n",
    "\n",
    "## convert with function --> allows automate and double check units\n",
    "# chem_aqui_ann_subset['ConvertedResultMeasureValue'] = convert_concentration( \n",
    "#     zip(chem_aqui_ann_subset['ResultMeasureValue'], chem_aqui_ann_subset['ResultMeasure/MeasureUnitCode']) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aquifers = mwgd['AquiferName'].unique()\n",
    "# aquifers = aquifers[ ( ~pd.isnull(aquifers) ) & (aquifers != 'Other aquifers') ]\n",
    "\n",
    "# ## create an outer loop?\n",
    "# aqui_of_int  = aquifers[0]\n",
    "\n",
    "# # subset by aquifer\n",
    "# aquifer_cond = chem_annual_subset['AquiferName'] == aqui_of_int\n",
    "# aqui_chem_ann_subset = chem_annual_subset.loc[ (aquifer_cond), : ]\n",
    "\n",
    "\n",
    "# subset sampled\n",
    "# sampled_cond = ( (above_lim_subset['ResultMeasureValue'].astype(float) > 0) )\n",
    "# above_lim_subset = mwgd.loc[ mwgd['ResultMeasureValue'].str.contains('<'), :]\n",
    "\n",
    "# Early plot information\n",
    "# cen_lon = mwgd.bounds.maxx.max() - mwgd.bounds.minx.min() # greatest longitude value - smallest longitude value \n",
    "# min_lat = mwgd.bounds.miny.min() # minimum latitude \n",
    "# max_lat = mwgd.bounds.miny.max() # maximum latitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the geoplot documentation\n",
    "\n",
    "# A more interesting scale is the logarithmic scale. This scale works very well when the data in question is\n",
    "# \"log-linear\", that is, it is distributed linearly with respect to its own logarithm. In our demonstratory case the\n",
    "# data is linear and not logorithmic in shape, so this doesn't come out too well, but in other cases using the logorithm\n",
    "# is the way to go.\n",
    "def log_scale(minval, maxval):\n",
    "    # The minimum value in this dataset is -112, so we need to adjust inputs.\n",
    "    def scalar(val):\n",
    "        val = val + abs(minval) + 1\n",
    "        return np.log10(val)\n",
    "    return scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cartopy.mpl.geoaxes.GeoAxesSubplot at 0x1668da23c50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import geoplot\n",
    "import geoplot as gplt\n",
    "import geoplot.crs as gcrs\n",
    "from cartopy.io.img_tiles import Stamen\n",
    "\n",
    "#plotting the information\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = plt.subplot(111, projection=gcrs.Mercator( central_longitude=ca_max_lon-ca_min_lon, \n",
    "                                                 min_latitude= ca_min_lat, \n",
    "                                                 max_latitude= ca_max_lat)\n",
    "                 )\n",
    "# add base layer image\n",
    "ax1.add_image( Stamen('terrain-background'), 8)\n",
    "# add water quality data points\n",
    "gplt.pointplot( chem_aqui_ann_subset, \n",
    "                projection=gcrs.Mercator(),\n",
    "                hue='AquiferName', \n",
    "                categorical=True,\n",
    "                legend=True,                \n",
    "                edgecolor='black', linewidth=0.5,\n",
    "                scale='NormalizedResultMeasureValue',\n",
    "                legend_var='scale',\n",
    "                limits=(1,5),\n",
    "#                 scale_func=log_scale,\n",
    "                ax=ax1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_aqui_ann_subset['ResultMeasureValue'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chem_aqui_ann_subset['NormalizedResultMeasureValue'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_aqui_ann_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(chem_aqui_ann_subset.loc['USGS-323932117050801','ResultMeasure/MeasureUnitCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwgd['CharacteristicName'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
